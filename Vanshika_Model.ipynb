{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vanshika_Model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwDJjGu05mun",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kLW9Yl1492y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c6c1ed3-3aa5-44ca-c554-030708369722"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "\n",
        "def combine_csv():\n",
        "    data_files = sorted(glob('Dataset/*.pcap_ISCX.csv'))\n",
        "    ids = pd.read_csv(data_files[0])\n",
        "    for i in range(1, len(data_files)):\n",
        "        dfi = pd.read_csv(data_files[i])\n",
        "        dfi.dropna(axis=0, how='any', inplace=True)\n",
        "        ids = pd.concat((ids, dfi), ignore_index=True)\n",
        "\n",
        "    del dfi\n",
        "    print(ids.head())\n",
        "    print(ids.head())\n",
        "    ids.to_csv('Dataset/combined_data.csv', index=False)\n",
        "\n",
        "\n",
        "def resize_dataset():\n",
        "    ids = pd.read_csv('./Dataset/combined_data.csv',\n",
        "                      dtype={'Flow Bytes/s': str, ' Flow Packets/s': str})\n",
        "    labels_to_drop = {'BENIGN': 0.1, 'DoS Hulk': 0.3, 'DDoS': 0.3, 'PortScan': 0.3}\n",
        "    for label in labels_to_drop:\n",
        "        df = ids.loc[ids[' Label'] == label]\n",
        "        ids.drop(ids.index[ids[' Label'] == label], inplace=True)\n",
        "        df = df.sample(frac=labels_to_drop[label])\n",
        "        ids = pd.concat((ids, df), ignore_index=True)\n",
        "\n",
        "    ids = ids.sample(frac=1, random_state=42)\n",
        "    ids.reset_index(drop=True, inplace=True)\n",
        "    ids['Flow Bytes/s'] = ids['Flow Bytes/s'].str.strip()\n",
        "    ids[' Flow Packets/s'] = ids[' Flow Packets/s'].str.strip()\n",
        "    ids = ids.astype({'Flow Bytes/s': float, ' Flow Packets/s': float})\n",
        "    ids.columns = ids.columns.str.strip()\n",
        "    ids.dropna(inplace=True)\n",
        "    indices_to_keep = ~ids.isin([np.nan, np.inf, -np.inf]).any(axis=1)\n",
        "    ids = ids[indices_to_keep]\n",
        "    ids.to_csv('Dataset/resized_data.csv', index=False)\n",
        "    return ids\n",
        "\n",
        "\n",
        "def binary_label_encoder(y):\n",
        "    '''\n",
        "    converts multiclass labels to binary labels\n",
        "    '''\n",
        "    y[\"BinaryLabel\"] = (y[\"Label\"] != 'BENIGN').astype(int)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "def split_dataset(df):\n",
        "    '''\n",
        "    Takes a dataframe df and splits it in 0.7:0.15:0.15 ratio for training, cross-validation and test sets.\n",
        "    '''\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "    for train_index, test_index in split.split(df, df['BinaryLabel']):\n",
        "        train = df.loc[train_index]\n",
        "        test = df.loc[test_index]\n",
        "\n",
        "    split = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
        "    for test_index, cv_index in split.split(test, test['BinaryLabel']):\n",
        "        test = df.loc[train_index]\n",
        "        cv = df.loc[cv_index]\n",
        "\n",
        "    return train, cv, test\n",
        "\n",
        "\n",
        "def main():\n",
        "    if not os.path.isfile('Dataset/combined_data.csv'):\n",
        "        combine_csv()\n",
        "    if not os.path.isfile('Dataset/resized_data.csv'):\n",
        "        resize_dataset()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8qrA3gf8ff1",
        "colab_type": "text"
      },
      "source": [
        "# Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4CCOoBu8dFh",
        "colab_type": "code",
        "outputId": "d60fe97a-3fc5-44f7-8611-9f6767311807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import chi2\n",
        "#from preprocessing import binary_label_encoder, split_dataset\n",
        "\n",
        "def get_x_y(df):\n",
        "    y = train[['BinaryLabel']]\n",
        "    X = train.drop(['Label', 'BinaryLabel'], axis=1, inplace=False)\n",
        "    y = y['BinaryLabel'].values\n",
        "    return X, y\n",
        "\n",
        "\n",
        "dataset = pd.read_csv(\"/content/drive/My Drive/Dataset/resized_data.csv\")\n",
        "dataset = binary_label_encoder(dataset)\n",
        "train, cv, test = split_dataset(dataset)\n",
        "\n",
        "X_train, y_train = get_x_y(train)\n",
        "cols = X_train.columns.tolist()\n",
        "mm_scaler = MinMaxScaler()\n",
        "X_new = X_train\n",
        "X_new[cols] = mm_scaler.fit_transform(X_train[cols])\n",
        "\n",
        "\n",
        "X_cv, y_cv = get_x_y(cv)\n",
        "X_cv[cols] = mm_scaler.transform(X_cv[cols])\n",
        "\n",
        "# Features needed can be changed below to get the top 'k'\n",
        "# features for model training\n",
        "features_needed = 15\n",
        "\n",
        "######################################################################\n",
        "\n",
        "print(\"Selection based on Pearson Correlation\")\n",
        "\n",
        "\n",
        "def cor_selector(X, y, num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:, np.argsort(np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "\n",
        "\n",
        "cor_support, cor_feature = cor_selector(X_new, y_train, features_needed)\n",
        "print(str(len(cor_feature)), 'selected features')\n",
        "print(cor_feature)\n",
        "\n",
        "#####################################################################\n",
        "\n",
        "print(\"Selection based on chi square distibution\")\n",
        "\n",
        "chi_selector = SelectKBest(chi2, k=features_needed)\n",
        "X_kbest_features = chi_selector.fit_transform(X_new, y_train)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X_new.loc[:, chi_support].columns.tolist()\n",
        "print(str(len(chi_feature)), 'selected features')\n",
        "print(chi_feature)\n",
        "\n",
        "\n",
        "# # More Raw Approach - Leaving the first 2 valued and\n",
        "# # last NaN valued features, all other features are\n",
        "# # dependent and can be considered for training\n",
        "\n",
        "# print(\"Raw Approach of chi square\")\n",
        "# chi_scores = chi2(X_new,y)\n",
        "# p_values = pd.Series(chi_scores[1],index = X_new.columns)\n",
        "# p_values.sort_values(ascending = False , inplace = True)\n",
        "# # p_values.plot.bar()\n",
        "# # print(p_values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selection based on Pearson Correlation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[:, None]\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
            "  c /= stddev[None, :]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "20 selected features\n",
            "['Flow Duration', 'PSH Flag Count', 'Flow IAT Std', 'Idle Min', 'Idle Mean', 'Flow IAT Max', 'Fwd IAT Max', 'Idle Max', 'Average Packet Size', 'Fwd IAT Std', 'Packet Length Mean', 'Packet Length Variance', 'Max Packet Length', 'Packet Length Std', 'Min Packet Length', 'Avg Bwd Segment Size', 'Bwd Packet Length Mean', 'Bwd Packet Length Min', 'Bwd Packet Length Max', 'Bwd Packet Length Std']\n",
            "Selection based on chi square distibution\n",
            "20 selected features\n",
            "['Destination Port', 'Flow Duration', 'Bwd Packet Length Max', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Total', 'Fwd IAT Std', 'Fwd IAT Max', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'PSH Flag Count', 'URG Flag Count', 'Avg Bwd Segment Size', 'Idle Mean', 'Idle Max', 'Idle Min']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRdNhuCk9bKs",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TETeYm5gFEwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhQFksc99B0u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x1,y1 = X_new[chi_feature], y_train\n",
        "x_test,y_test = X_cv[chi_feature],y_cv\n",
        "#X_new.iloc[:,chi_support]  \n",
        "#x2,y2 = X_new[cor_feature],y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHs5QSbA9XnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = torch.tensor(x1.values.astype(np.float32))\n",
        "train_target = torch.tensor(y1.astype(np.float32))\n",
        "\n",
        "train_dataset = data_utils.TensorDataset(train,train_target)\n",
        "train_loader = data_utils.DataLoader(dataset= train_dataset , batch_size = 64, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxdOQo0yV5NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = torch.tensor(x_test.values.astype(np.float32))\n",
        "test_target = torch.tensor(y_test.astype(np.float32))\n",
        "\n",
        "test_dataset = data_utils.TensorDataset(test,test_target)\n",
        "test_loader = data_utils.DataLoader(dataset = test_dataset,batch_size =1, shuffle= False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tD-64Y9Hb4f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net,self).__init__()\n",
        "    self.fc1 = nn.Linear(15,34)\n",
        "    self.fc2 = nn.Linear(34,52)\n",
        "    self.fc3 = nn.Linear(52,1)\n",
        "    \n",
        "    self.relu = nn.ReLU()\n",
        "    self.dropout = nn.Dropout(p=0.1)\n",
        "    self.batchnorm1 = nn.BatchNorm1d(34)\n",
        "    self.batchnorm2 = nn.BatchNorm1d(52)\n",
        "\n",
        "    # define forward loop\n",
        "  def forward(self, inputs):\n",
        "    x = self.relu(self.fc1(inputs))\n",
        "    x = self.batchnorm1(x)\n",
        "    x = self.relu(self.fc2(x))\n",
        "    x = self.batchnorm2(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O62b4mnIQBi",
        "colab_type": "code",
        "outputId": "bf0b7ee0-af61-4656-c4e5-755768a1e638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "model = Net()\n",
        "print(model)\n",
        "Loss_function = nn.BCEWithLogitsLoss()\n",
        "Optimizer_with_Regularization_Function = optim.Adam(model.parameters(),lr=0.01)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=15, out_features=34, bias=True)\n",
            "  (fc2): Linear(in_features=34, out_features=52, bias=True)\n",
            "  (fc3): Linear(in_features=52, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(34, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg2nIcplPjoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_acc(y_pred,y_batch):\n",
        "  y_pred_rounded = torch.round(torch.sigmoid(y_pred))\n",
        "\n",
        "\n",
        "  correct_result_sum = (y_pred_rounded == y_batch).sum().float()\n",
        "  acc = correct_result_sum / y_batch.shape[0]\n",
        "  acc = torch.round(100* acc)\n",
        "   \n",
        "  return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbD_CAd_Pxvl",
        "colab_type": "code",
        "outputId": "018de74f-6f76-4a39-f4ed-2d15cf2d9c71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "model.train()\n",
        "epochs = 20\n",
        "for i in range(1,epochs+1):\n",
        "  epochs_loss = 0\n",
        "  epochs_acc = 0\n",
        "  for x_batch,y_batch in train_loader:\n",
        "    Optimizer_with_Regularization_Function.zero_grad()\n",
        "\n",
        "    y_pred = model(x_batch)\n",
        "\n",
        "    #print(y_pred.size())\n",
        "    #print(y_batch.size())\n",
        "    \n",
        "    loss = Loss_function(y_pred,y_batch.unsqueeze(1))\n",
        "    acc = binary_acc(y_pred,y_batch.unsqueeze(1))\n",
        "\n",
        "    #backpropagation\n",
        "    loss.backward()\n",
        "    Optimizer_with_Regularization_Function.step() # 1 time updation\n",
        "    \n",
        "    epochs_loss += loss.item()\n",
        "    epochs_acc += acc.item()\n",
        "\n",
        "\n",
        "  print(f'Epoch {i}: | Loss: {epochs_loss/len(train_loader): .5f} | Acc: {epochs_acc/len(train_loader): .3f}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: | Loss:  0.25563 | Acc:  87.928\n",
            "Epoch 2: | Loss:  0.23285 | Acc:  88.712\n",
            "Epoch 3: | Loss:  0.22992 | Acc:  88.706\n",
            "Epoch 4: | Loss:  0.22670 | Acc:  88.776\n",
            "Epoch 5: | Loss:  0.22771 | Acc:  88.689\n",
            "Epoch 6: | Loss:  0.22650 | Acc:  88.818\n",
            "Epoch 7: | Loss:  0.22695 | Acc:  88.761\n",
            "Epoch 8: | Loss:  0.22264 | Acc:  88.931\n",
            "Epoch 9: | Loss:  0.22176 | Acc:  88.905\n",
            "Epoch 10: | Loss:  0.21904 | Acc:  89.064\n",
            "Epoch 11: | Loss:  0.21601 | Acc:  89.121\n",
            "Epoch 12: | Loss:  0.21451 | Acc:  89.085\n",
            "Epoch 13: | Loss:  0.21864 | Acc:  89.003\n",
            "Epoch 14: | Loss:  0.21209 | Acc:  89.269\n",
            "Epoch 15: | Loss:  0.21800 | Acc:  88.984\n",
            "Epoch 16: | Loss:  0.21334 | Acc:  89.344\n",
            "Epoch 17: | Loss:  0.21311 | Acc:  89.447\n",
            "Epoch 18: | Loss:  0.21093 | Acc:  89.552\n",
            "Epoch 19: | Loss:  0.21427 | Acc:  89.358\n",
            "Epoch 20: | Loss:  0.21152 | Acc:  89.386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYQuiWedP2YX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "\n",
        "y_pred_list = []\n",
        "y_correct_list = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for x_batch,y_batch in test_loader:\n",
        "    y_pred = model(x_batch)\n",
        "    y_pred = torch.sigmoid(y_pred)\n",
        "    y_pred_list.append(y_pred.cpu().numpy())\n",
        "    y_correct_list.append(y_batch.numpy())   #numpy arrays will be formed,will convert arrays into list\n",
        "\n",
        "\n",
        "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
        "y_correct_list = [a.squeeze().tolist() for a in y_correct_list]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDM2VW3GYFEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_ana = []\n",
        "y_pred_non = []\n",
        "\n",
        "len_of_list = len(y_pred_list)\n",
        "\n",
        "for i in range(0,len_of_list):\n",
        "  if y_correct_list[i] == 0:\n",
        "    y_pred_non.append(y_pred_list[i])\n",
        "  else:\n",
        "    y_pred_ana.append(y_pred_list[i])\n",
        "\n",
        "y_pred_non = [i*100 for i in y_pred_non]\n",
        "y_pred_ana = [i*100 for i in y_pred_ana]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpO9BRx2ZdwC",
        "colab_type": "code",
        "outputId": "7bc9816a-e897-4013-85ed-d4e635914d6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "data = y_pred_non\n",
        "bins = np.linspace(0, 100, 25, endpoint=True)\n",
        "plt.hist(data,bins,color='green',alpha=0.5,label='non_spam')\n",
        "\n",
        "data1 = y_pred_ana\n",
        "plt.hist(data1,bins,color='red',alpha=0.6,label='spam')\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05,1),loc='upper left')\n",
        "plt.xlabel('Anamoaly Score')\n",
        "plt.ylabel('Occurences')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Occurences')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DNKaad1aLl9",
        "colab_type": "code",
        "outputId": "32c2ee61-a689-4902-f757-e935feb3fc2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "y_pred_list = np.array(y_pred_list)\n",
        "\n",
        "print(classification_report(y_test,y_pred_list.round(),target_names = [\"Normal\",\"Abnormal\"]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.86      0.98      0.92     34069\n",
            "    Abnormal       0.97      0.82      0.89     29203\n",
            "\n",
            "    accuracy                           0.90     63272\n",
            "   macro avg       0.92      0.90      0.90     63272\n",
            "weighted avg       0.91      0.90      0.90     63272\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8_nzwf_atL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}